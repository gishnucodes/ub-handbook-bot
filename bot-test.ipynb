{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-21T19:21:44.302566Z",
     "start_time": "2025-01-21T19:21:44.287573Z"
    }
   },
   "source": [
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from markitdown import MarkItDown\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = 'AIzaSyCO_JGvibGVMWHZNI6mxv-qc2wmdChLABk'\n",
    "\n",
    "def load_file():\n",
    "    md = MarkItDown()\n",
    "    result = md.convert(\"grad-handbook-2024.pdf\")\n",
    "    docs = [{\"page_content\": txt} for txt in re.split(r\"(?=\\n##)\", result.text_content)]\n",
    "    documents = [item['page_content'] for item in docs]\n",
    "    return documents\n",
    "\n",
    "def get_vector_store(documents):\n",
    "    # Initialize Gemini embeddings\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    # Split the documents into chunks\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    # texts = text_splitter.split_texts(documents)\n",
    "    docstest = text_splitter.create_documents(documents)\n",
    "    # Create the vector store\n",
    "    vectorstore = FAISS.from_documents(docstest, embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "def init_vector_store():\n",
    "    documents = load_file()\n",
    "    vectorstore = get_vector_store(documents)\n",
    "    return vectorstore\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T19:22:46.468378Z",
     "start_time": "2025-01-21T19:22:46.220445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ],
   "id": "82326ab2a32e0c79",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T19:23:04.284369Z",
     "start_time": "2025-01-21T19:22:58.160057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key='AIzaSyCO_JGvibGVMWHZNI6mxv-qc2wmdChLABk')\n",
    "vectorstore = init_vector_store()\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ],
   "id": "30684f2020b4296b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1446, which is longer than the specified 1000\n",
      "Created a chunk of size 2224, which is longer than the specified 1000\n",
      "Created a chunk of size 1139, which is longer than the specified 1000\n",
      "Created a chunk of size 1016, which is longer than the specified 1000\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3a40938771e2a600"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
